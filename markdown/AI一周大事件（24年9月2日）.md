---
categories:
- 笔记
- 人工智能
date: 2024-09-02 13:19:38
title: AI一周大事件（24年9月2日）
img: https://myblog-1257298572.cos.ap-shanghai.myqcloud.com//img%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240902212953.png
draft: true
---

# AI一周大事件（24年9月2日）

### 人大北邮上海AI Lab等提出多模态分割新方法 | ECCV2024

已有研究正在做的：（各自从视觉、文本和音频线索的角度出发）

- **视频对象分割**（VOS，Video Object Segmentation）：通常以第一帧中的对象掩码作为参考，指导后续帧中特定对象的分割。（严重依赖于第一帧的精确标注）
- **视频对象参考分割**（Ref-VOS，Referring Video Object Segmentation）：基于自然语言描述分割视频中的物体，取代了VOS中的掩码标注。（虽然更易于访问，但能力有限）
- **视听分割**（AVS，Audio-Visual Segmentation）：以音频为指导来分割视频中发声的物体。（无法应对不发声的物体）

而新方法Ref-AVS，整合了**多个模态（文本，音频和视觉）**之间的关系来适应更真实的**动态视听场景**。

![微信图片_20240902212654](https://myblog-1257298572.cos.ap-shanghai.myqcloud.com//img%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240902212654.png)

除此之外，他们还构建了数据集Ref-AVS Bench，共有40020个视频帧，包含6888个物体和20261个指代表达式（Reference Expression）。

### OpenCity大模型预测交通路况，零样本下表现出色，来自港大百度

相比于传统方法，OpenCity具有以下特点：

- 通用时空建模：OpenCity旨在有效处理不同空间区域和时间城市交通模式的固有多样性和变化。
- 卓越的零样本预测能力：与仅在目标区域训练的全样本模型相比，OpenCity展示了更优越的性能。这种显著的零样本能力突出了模型学习泛化表征的能力，使其能够无需广泛重新训练或微调即可无缝应用于新的交通环境。
- 快速的情境适应能力：OpenCity在不同天的时空预测任务中展现了广泛的适用性。模型只需快速微调就能适应上下文，可以无缝部署在各种场景中。
- 可扩展性：OpenCity展示了有希望的缩放定律，表明该模型有潜力在最小的额外训练或微调需求下有效地扩展和适应新的、以前未见过的场景。

![微信图片_20240902212953](https://myblog-1257298572.cos.ap-shanghai.myqcloud.com//img%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240902212953.png)

可借鉴的地方：时空上下文编码，类似于Transformer中的位置编码。

### Mamba最新综述

Mamba是一种新的选择性结构状态空间模型，在长序列建模任务中表现出色。Mamba通过全局感受野和动态加权，缓解了卷积神经网络的建模约束，并提供了类似于Transformers的高级建模能力。至关重要的是，它实现了这一点，而不会产生通常与Transformer相关的二次计算复杂性。由于其相对于前两种主流基础模型的优势，曼巴展示了其作为视觉基础模型的巨大潜力。研究人员正在积极地将曼巴应用于各种计算机视觉任务，导致了许多新兴的工作。为了跟上计算机视觉的快速发展，本文旨在对视觉曼巴方法进行全面综述。本文首先描述了原始曼巴模型的公式。随后，我们对视觉曼巴的综述深入研究了几个具有代表性的骨干网络，以阐明视觉曼巴中的核心见解。然后，我们使用不同的模式对相关作品进行分类，包括图像、视频、点云、多模态等。具体来说，对于图像应用程序，我们将它们进一步组织成不同的任务，以促进更结构化的讨论。最后，我们讨论了视觉曼巴的挑战和未来的研究方向，为这个快速发展的领域的未来研究提供了见解。

标题：A Survey of Mamba

作者：Haohao Qu, Liangbo Ning, Rui An, Wenqi Fan, Tyler Derr, Xin Xu, Qing Li

机构：香港理工大学、范德比尔特大学

原文链接：https://arxiv.org/abs/2408.01129

### 小波变换+Transformer

论文名：Spiking Wavelet Transformer

方法：论文提出了一种名为SWformer的新型神经网络架构，它结合了SNNs和DWT，以有效学习时空频率特征。SWformer的核心组件是FATM，它通过三个分支处理输入：1.尖峰小波学习器用于时空频率域学习，2.基于卷积的 learner 用于空间特征提取，以及3.尖峰逐点卷积用于跨通道信息聚合。此外，SWformer采用负尖峰动态进一步增强频率表示，使其在捕获高频视觉组件方面超越了传统的尖峰Transformer。

Spiking Wavelet Transformer（SWformer）处理的是脉冲神经网络（SNNs）的数据，这类数据模仿了生物神经系统中的事件驱动处理方式。在SNNs中，信息通过所谓的“脉冲”或“尖峰”来表示，这些脉冲是二进制的，类似于神经元在达到一定阈值时发放的动作电位。

以下是一些SWformer可以处理的数据类型的例子：

1. **静态图像数据**：在处理静态图像时，SWformer会将图像重复多次以形成时间序列，然后通过SNNs进行处理。例如，它可以处理ImageNet数据集中的图像，这是一个广泛用于图像识别的数据库，包含数百万张标记的图像。
2. **神经形态数据集**：这些数据集由事件相机捕获，它们以高时间分辨率记录像素强度变化，仅在像素亮度显著变化时生成数据。例如，CIFAR10-DVS是一个从CIFAR-10静态图像数据集转换而来的事件流数据集，用于模拟动态视觉传感。
3. **视频数据**：SWformer可以处理视频数据，将其转换为一系列脉冲信号。在视频处理中，每一帧或帧的一部分可以转换为脉冲，SNNs能够对这些脉冲序列进行编码和解码，以识别视频中的对象和动作。
4. **传感器数据**：在物联网（IoT）应用中，各种传感器（如加速度计、陀螺仪、温度传感器等）可以生成时间序列数据。SWformer可以处理这些数据，用于模式识别、异常检测或预测性维护。
5. **医学信号**：例如，脑电图（EEG）或心电图（ECG）信号，这些信号以时间序列的形式记录了大脑或心脏的电活动。SWformer可以处理这些脉冲序列，用于诊断或监测健康状况。

SWformer通过其独特的架构设计，能够有效地从这些不同类型的数据中学习空间和频率特征，而不依赖于传统的密集型计算，这使得它在能效和实时处理方面具有潜在优势。

总结：这玩意很牛，要代替我们平常所用的标准神经网络，目前应该还在雏形，先观望一下。

小波+Transformer的文章还有一些，这一块我会总结一下单独写个调研报告。
